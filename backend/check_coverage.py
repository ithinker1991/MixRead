#!/usr/bin/env python3
"""
æ£€æŸ¥æµ‹è¯•æ®µè½çš„ä¸­æ–‡è¦†ç›–ç‡
Check Chinese translation coverage for test paragraph
"""

import json
from pathlib import Path

# Load dictionary
dict_path = Path(__file__).parent / "chinese_dict.json"
with open(dict_path, 'r', encoding='utf-8') as f:
    chinese_dict = json.load(f)

# Test paragraph words
test_paragraph = """
Climate change represents one of the most consequential challenges facing humanity.
The ramifications extend across multiple domains including agriculture infrastructure and biodiversity.
Scientists have documented unprecedented temperature fluctuations and volatile weather patterns.
Mitigating these effects requires comprehensive international cooperation and substantial
investment in sustainable technologies. The imperative to act is becoming increasingly urgent
as we observe accelerating environmental degradation.
"""

# Extract unique words
import re
words = re.findall(r'\b[a-z]+\b', test_paragraph.lower())
unique_words = sorted(set(words))

print(f"ğŸ“Š è¦†ç›–ç‡åˆ†æ Coverage Analysis")
print(f"=" * 60)
print(f"\næ€»å•è¯æ•° Total unique words: {len(unique_words)}")

# Check which words have Chinese
has_chinese = []
no_chinese = []

for word in unique_words:
    if word in chinese_dict:
        has_chinese.append(word)
    else:
        no_chinese.append(word)

print(f"æœ‰ä¸­æ–‡ Has Chinese: {len(has_chinese)} ({len(has_chinese)/len(unique_words)*100:.1f}%)")
print(f"æ— ä¸­æ–‡ No Chinese: {len(no_chinese)} ({len(no_chinese)/len(unique_words)*100:.1f}%)")

print(f"\nâœ… æœ‰ä¸­æ–‡çš„å•è¯ ({len(has_chinese)}):")
for word in has_chinese:
    print(f"   {word:20} â†’ {chinese_dict[word]}")

print(f"\nâŒ ç¼ºå°‘ä¸­æ–‡çš„å•è¯ ({len(no_chinese)}):")
for word in no_chinese:
    print(f"   {word}")

# Check for plural/form issues
print(f"\nğŸ” è¯å½¢å˜åŒ–é—®é¢˜ Word Form Issues:")
potential_matches = []
for word in no_chinese:
    # Check if base form exists
    if word.endswith('s') and word[:-1] in chinese_dict:
        potential_matches.append((word, word[:-1], chinese_dict[word[:-1]]))
    elif word.endswith('es') and word[:-2] in chinese_dict:
        potential_matches.append((word, word[:-2], chinese_dict[word[:-2]]))
    elif word.endswith('ing') and word[:-3] in chinese_dict:
        potential_matches.append((word, word[:-3], chinese_dict[word[:-3]]))
    elif word.endswith('ing') and word[:-3] + 'e' in chinese_dict:
        potential_matches.append((word, word[:-3] + 'e', chinese_dict[word[:-3] + 'e']))
    elif word.endswith('ed') and word[:-2] in chinese_dict:
        potential_matches.append((word, word[:-2], chinese_dict[word[:-2]]))
    elif word.endswith('ed') and word[:-1] in chinese_dict:
        potential_matches.append((word, word[:-1], chinese_dict[word[:-1]]))

if potential_matches:
    print(f"\n   å‘ç° {len(potential_matches)} ä¸ªè¯å½¢å˜åŒ–å¯¼è‡´çš„æœªåŒ¹é…:")
    for word, base, translation in potential_matches:
        print(f"   {word:20} â†’ åŸºç¡€å½¢å¼: {base} ({translation})")
else:
    print("   æœªå‘ç°æ˜æ˜¾çš„è¯å½¢å˜åŒ–é—®é¢˜")

print(f"\nğŸ“ å»ºè®® Recommendations:")
if potential_matches:
    print(f"   1. è¯å…¸ä¸­æ·»åŠ è¯å½¢å˜åŒ– (å¤æ•°ã€åŠ¨è¯å˜ä½ç­‰)")
    print(f"   2. æˆ–åœ¨å‰ç«¯å®ç°è¯å¹²æå– (stemming)")
if len(no_chinese) - len(potential_matches) > 0:
    print(f"   3. è¡¥å……ç¼ºå¤±çš„ {len(no_chinese) - len(potential_matches)} ä¸ªåŸºç¡€è¯æ±‡")
