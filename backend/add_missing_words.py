#!/usr/bin/env python3
"""
æ·»åŠ ç¼ºå¤±çš„å•è¯ï¼ˆè¯å½¢å˜åŒ– + å¸¸ç”¨è¯ï¼‰
Add missing words (word forms + common words)
"""

import json
from pathlib import Path

# Load existing dictionary
dict_path = Path(__file__).parent / "chinese_dict.json"
with open(dict_path, 'r', encoding='utf-8') as f:
    chinese_dict = json.load(f)

print(f"ğŸ“š å½“å‰è¯å…¸: {len(chinese_dict)} ä¸ªå•è¯")

# Add missing word forms and common words
new_words = {
    # Word forms from test paragraph
    "challenges": "æŒ‘æˆ˜",
    "effects": "å½±å“",
    "patterns": "æ¨¡å¼",
    "requires": "éœ€è¦",

    # Additional word forms for existing words
    "technologies": "æŠ€æœ¯",
    "observations": "è§‚å¯Ÿ",
    "measurements": "æµ‹é‡",
    "evaluations": "è¯„ä¼°",
    "investigations": "è°ƒæŸ¥",
    "explorations": "æ¢ç´¢",
    "applications": "åº”ç”¨",
    "definitions": "å®šä¹‰",
    "examples": "ä¾‹å­",
    "sentences": "å¥å­",
    "systems": "ç³»ç»Ÿ",
    "processes": "è¿‡ç¨‹",
    "methods": "æ–¹æ³•",
    "approaches": "æ–¹æ³•",
    "strategies": "ç­–ç•¥",
    "solutions": "è§£å†³æ–¹æ¡ˆ",
    "problems": "é—®é¢˜",
    "opportunities": "æœºä¼š",
    "emissions": "æ’æ”¾",

    # Missing content words from test paragraph
    "humanity": "äººç±»",
    "documented": "è®°å½•çš„",
    "domains": "é¢†åŸŸ",
    "environmental": "ç¯å¢ƒçš„",
    "facing": "é¢å¯¹",
    "increasingly": "æ—¥ç›Š",
    "international": "å›½é™…çš„",
    "observe": "è§‚å¯Ÿ",
    "represents": "ä»£è¡¨",
    "scientists": "ç§‘å­¦å®¶",
    "urgent": "ç´§æ€¥çš„",
    "becoming": "å˜å¾—",
    "act": "è¡ŒåŠ¨",

    # Additional common words
    "across": "æ¨ªè·¨",
    "including": "åŒ…æ‹¬",
    "these": "è¿™äº›",
    "most": "æœ€",
    "one": "ä¸€ä¸ª",

    # More verb forms
    "requires": "éœ€è¦",
    "provides": "æä¾›",
    "includes": "åŒ…æ‹¬",
    "contains": "åŒ…å«",
    "involves": "æ¶‰åŠ",
    "affects": "å½±å“",
    "influences": "å½±å“",
    "determines": "å†³å®š",
    "establishes": "å»ºç«‹",
    "maintains": "ç»´æŒ",
    "improves": "æ”¹å–„",
    "enhances": "å¢å¼º",
    "increases": "å¢åŠ ",
    "decreases": "å‡å°‘",
    "reduces": "å‡å°‘",
    "expands": "æ‰©å±•",
    "extends": "å»¶ä¼¸",
    "limits": "é™åˆ¶",
    "restricts": "é™åˆ¶",
    "prevents": "é˜²æ­¢",

    # Adjective forms
    "various": "å„ç§å„æ ·çš„",
    "specific": "å…·ä½“çš„",
    "general": "ä¸€èˆ¬çš„",
    "common": "å¸¸è§çš„",
    "typical": "å…¸å‹çš„",
    "unique": "ç‹¬ç‰¹çš„",
    "special": "ç‰¹æ®Šçš„",
}

# Merge with existing dictionary
added_count = 0
for word, translation in new_words.items():
    if word not in chinese_dict:
        chinese_dict[word] = translation
        added_count += 1
        print(f"  âœ… æ·»åŠ : {word} â†’ {translation}")
    else:
        print(f"  â­ï¸  å·²å­˜åœ¨: {word}")

# Save updated dictionary
with open(dict_path, 'w', encoding='utf-8') as f:
    json.dump(chinese_dict, f, ensure_ascii=False, indent=2)

print(f"\nâœ… æ›´æ–°å®Œæˆ!")
print(f"   æ–°å¢: {added_count} ä¸ªå•è¯")
print(f"   æ€»è®¡: {len(chinese_dict)} ä¸ªå•è¯")
