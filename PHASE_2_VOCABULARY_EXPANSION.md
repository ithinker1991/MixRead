# Phase 2: 词库扩展方案分析与讨论

## 一、现状分析

### 当前词库规模
```
CEFR 词库（data/cefr_words.json）
├─ A1: 898 词
├─ A2: 1,154 词
├─ B1: 2,202 词
├─ B2: 2,606 词
└─ 总计: 6,860 词

中文翻译库（chinese_dict.json）
└─ 总计: ~800 词（覆盖率: 11.6%）
```

### 存在的问题
- ❌ 词库覆盖不足，常见词汇缺失（如 "proficiency", "exposure" 等）
- ❌ C1/C2 级别词汇几乎没有
- ❌ 专业术语和低频词缺乏
- ❌ 中文翻译覆盖率低（只有 11.6%）

### MVP 用户反馈
- 用户想标记的词经常不在库中
- 大量高频词汇缺失，降低用户体验

---

## 二、可行方案对比

### 🟢 方案 A: 扩展现有 CEFR 数据源

**方案描述：**
使用更完整的 CEFR-J 或 CEFR 扩展数据集（如果有更新版本）

**数据来源：**
- OpenLanguageProfiles CEFR-J 扩展版本
- CEFR 官方更新（如果有）
- 其他学术机构发布的 CEFR 词表

**工作量估计：** ⭐ 低（1-2天）

**成本：** 💰 零成本

**优点：**
- ✅ 学术标准化，难度级别可靠
- ✅ 现有下载脚本可直接复用
- ✅ 实施简单，风险低
- ✅ 与当前架构无缝集成

**缺点：**
- ❌ 可能只能扩展到 10,000-15,000 词（取决于可用数据源）
- ❌ 仍然无法覆盖所有词汇
- ❌ 需要处理数据格式转换

**最终结果：** 6,860 → ~12,000 词（如果有完整的 CEFR-J）

**适合场景：** 快速改善，成本最低

---

### 🟠 方案 B: 多数据源组合（推荐）

**方案描述：**
结合多个权威词汇来源，构建更全面的词库

**数据来源：**
```
1. CEFR-J 词库
   └─ 来源: OpenLanguageProfiles
   └─ 规模: 6,860-12,000 词
   └─ 提供: CEFR 难度等级

2. BNC（英国国家语料库）前 10,000 词
   └─ 来源: https://www.english-corpora.org/bnc/
   └─ 规模: 10,000 词
   └─ 提供: 高频词排序

3. COCA（当代美英语料库）前 10,000 词
   └─ 来源: https://www.english-corpora.org/coca/
   └─ 规模: 10,000 词（与 BNC 有重叠）
   └─ 提供: 现代英语高频词

4. 专业词汇库（可选）
   └─ 医学、科技、商业领域专用词汇
   └─ 规模: 3,000-5,000 词
```

**工作流程：**
```
1. 下载各数据源
2. 清洗和标准化数据格式
3. 合并重复项（优先级: CEFR > BNC > COCA）
4. 为缺失的 CEFR 难度等级补充
5. 生成最终的 merged_cefr_words.json
```

**工作量估计：** ⭐⭐ 中等（2-3天）

**成本：** 💰 零成本（所有数据源免费开放）

**优点：**
- ✅ 覆盖广泛（15,000-20,000 词）
- ✅ 兼具学术标准和实用性
- ✅ 同时利用难度级别和词频信息
- ✅ 成本极低
- ✅ 可重现性强（所有数据源公开）

**缺点：**
- ❌ 需要处理数据合并和冲突
- ❌ 仍然不能覆盖所有词汇
- ❌ 难度级别评估可能不够精确

**最终结果：** 6,860 → ~18,000-20,000 词

**适合场景：** 最优平衡点，快速改善且效果显著

---

### 🟡 方案 C: 开源词汇库 + API 缓存混合

**方案描述：**
本地维护核心词库（15,000-20,000 词），对不在库中的词动态调用开源 API

**技术架构：**
```
用户查询单词时：
  1. 检查本地 CEFR 词库 (6,860 词)
     ├─ 命中 → 返回本地数据 ✅ (快，<10ms)
     └─ 未命中 ↓

  2. 检查缓存库 (已查询过的词)
     ├─ 命中 → 返回缓存数据 ✅ (快，<10ms)
     └─ 未命中 ↓

  3. 调用开源 Dictionary API
     ├─ 如 Free Dictionary API (https://dictionaryapi.dev/)
     └─ 获取定义、例句、音标 (~200ms)

  4. AI 难度评估（可选）
     └─ 如果 API 返回的难度不清晰，使用本地规则评估
```

**实现细节：**
```
后端更改：
├─ 数据库新增表: cached_words
│  └─ word | cefr_level | definition | example | source | cached_at
├─ API 端点: /word/{word}
│  └─ 智能查询（本地 → 缓存 → API）
└─ 后台任务
   └─ 定期预加载常见词汇

前端无需修改（完全透明）
```

**工作量估计：** ⭐⭐⭐ 较高（4-5天）

**成本：**
- 💰 零成本（Free Dictionary API 免费）
- ⚡ 需要数据库空间（几 MB 级别）
- 🌐 需要稳定网络

**优点：**
- ✅ 理论上支持任意词汇（无限扩展）
- ✅ 实时获取最新定义
- ✅ 缓存策略保证快速响应
- ✅ 逐步积累词汇库（无需一次性加载）

**缺点：**
- ❌ 首次查询会有延迟（200ms+）
- ❌ 需要网络连接
- ❌ API 可能偶尔不可用
- ❌ 难度级别仍需手动或算法评估

**最终结果：** 6,860 本地 + 无限缓存词汇

**适合场景：** 长期可持续方案，未来导向

---

### 🔴 方案 D: AI 动态难度评估（高成本）

**方案描述：**
使用 Claude/GPT API 对任意词汇进行智能难度评估

**技术流程：**
```
用户查询单词时：
  1. 本地词库查询
     └─ 如果有 → 返回本地数据

  2. 调用 Claude API
     └─ 提示词: "评估这个英文单词对 CEFR B1 学习者的难度级别"
     └─ 返回: CEFR 等级、定义、例句、相关词汇

  3. 缓存结果
```

**工作量估计：** ⭐⭐⭐ 较高（3-4天）

**成本：**
- 💰 Claude API 调用费用（~$0.001 - $0.01 每次查询）
- 📊 成本因查询量而增加

**优点：**
- ✅ 最智能的难度评估
- ✅ 可获取高质量定义和例句
- ✅ 支持多语言翻译（如需要）
- ✅ 可定制化 CEFR 评估规则

**缺点：**
- ❌ 持续的 API 成本（MVP 阶段不适合）
- ❌ API 调用延迟较大（1-2 秒）
- ❌ 依赖外部服务可用性
- ❌ 不适合大规模预加载

**最终结果：** 动态支持所有词汇，但有成本

**适合场景：** 商业化后期，有 revenue 支持 API 成本

---

### 🟣 方案 E: 混合方案（最佳实践）

**方案描述：**
短期采用方案 B（快速覆盖 18,000 词），中期逐步引入方案 C（API 缓存）

**分阶段实施：**

```
时间线：
├─ 第 1 周: 实施方案 B
│  └─ 将词库扩展到 18,000-20,000 词
│  └─ 改善用户体验 (立即见效)
│
├─ 第 2-3 周: 准备方案 C 基础设施
│  └─ 数据库添加 cached_words 表
│  └─ 实现智能查询逻辑
│
├─ 第 4 周: 灰度发布方案 C
│  └─ 5% 用户流量使用 API 缓存
│  └─ 监控性能和准确率
│
└─ 第 5+ 周: 全量推出方案 C
   └─ 100% 用户流量支持动态词汇
   └─ 继续积累缓存词库
```

**工作量估计：** ⭐⭐⭐ 中等（分散在 4-5 周）

**成本：** 💰 零成本

**优点：**
- ✅ 立即改善用户体验（第 1 周见效）
- ✅ 长期无限扩展能力
- ✅ 完全开源，零成本
- ✅ 可持续维护和改进

**缺点：**
- ❌ 实施周期较长
- ❌ 需要反复迭代

**最终结果：**
- 短期: 18,000 词本地库
- 中期: 本地库 + 缓存库混合
- 长期: 支持任意词汇查询

**适合场景：** ⭐⭐⭐⭐⭐ 推荐！符合 MVP → Scale 的演进路径

---

## 三、数据源详细信息

### 数据源 1: CEFR-J（现有）
```
名称: OpenLanguageProfiles CEFR-J
URL: https://github.com/openlanguageprofiles/olp-en-cefrj
规模: 6,860-8,000 词（取决于版本）
质量: ⭐⭐⭐⭐⭐ (学术标准)
开源: ✅ MIT License
获取: git clone + CSV 处理
```

### 数据源 2: BNC Top Words
```
名称: British National Corpus (BNC) - Top 10,000 Words
URL: https://www.english-corpora.org/bnc/
规模: 10,000 词
质量: ⭐⭐⭐⭐⭐ (权威语料库)
开源: ✅ 免费公开（非商业用途）
获取: 网页爬取或 CSV 下载
排序: 按词频从高到低（可用于难度推断）
```

### 数据源 3: COCA Top Words
```
名称: Corpus of Contemporary American English (COCA) - Top 10,000 Words
URL: https://www.english-corpora.org/coca/
规模: 10,000 词
质量: ⭐⭐⭐⭐⭐ (权威语料库，美式英语)
开源: ✅ 免费公开（非商业用途）
获取: 网页爬取或 CSV 下载
排序: 按词频从高到低
```

### 数据源 4: Free Dictionary API
```
名称: Free Dictionary API
URL: https://dictionaryapi.dev/
规模: 支持 20,000+ 词汇
质量: ⭐⭐⭐⭐ (社区维护)
开源: ✅ 完全免费，GitHub 开源
速率限制: 无（本地部署选项可用）
返回数据: 定义、音标、词性、例句、同义词
```

### 数据源 5: 专业词汇库（可选）
```
医学词汇: https://github.com/mackenzieinstitute/medical-words
科技词汇: https://en.wiktionary.org/ (Technology category)
商业词汇: 可从 Corpus 中筛选

规模: 各领域 1,000-3,000 词
质量: ⭐⭐⭐ (取决于具体来源)
```

---

## 四、各方案数据对比

| 维度 | 方案 A | 方案 B | 方案 C | 方案 D | 方案 E |
|------|--------|--------|--------|--------|--------|
| **词汇覆盖** | 12K | 20K | 20K+无限 | 无限 | 20K+无限 |
| **难度标注** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **中文翻译** | 需要补充 | 需要补充 | 自动获取 | 自动获取 | 需要补充 |
| **查询速度** | <10ms | <10ms | 10-200ms | 1-2s | <10ms* |
| **实施复杂度** | ⭐ | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |
| **运维成本** | 💰💰 | 💰💰 | 💰 | 💰💰💰 | 💰💰 |
| **网络依赖** | ❌ | ❌ | ✅ | ✅ | ✅ (缓存优化) |
| **长期可维护性** | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |

*方案 E 中第一次查询有延迟，之后缓存命中返回 <10ms

---

## 五、核心决策要点

### ❓ 问题 1: 我们对词汇覆盖率的目标是多少？
- **18,000-20,000 词够吗？** 可覆盖日常英语 95% 以上
- **需要无限词汇吗？** 可以考虑方案 C/E 的长期规划

### ❓ 问题 2: 用户能否接受查询延迟？
- **第一次查询延迟 200ms 可以接受吗？**
- **还是需要零延迟？**

### ❓ 问题 3: 我们有多少时间投入？
- **立即需要改善（1 周）？** → 方案 A/B
- **可以分阶段实施（4-5 周）？** → 方案 E

### ❓ 问题 4: 未来会商业化吗？
- **预算有限？** → 方案 B （零成本）
- **有 API 预算？** → 方案 C/D

### ❓ 问题 5: 中文翻译的优先级如何？
- **当前仅 11.6% 有翻译**
- **是否需要批量补充？** （可配合任何方案）

---

## 六、建议的实施路径

### 🎯 推荐: 采用**方案 E（混合方案）**

**理由：**
1. ✅ 符合 MVP → Scale 的产品演进哲学
2. ✅ 第一周立即改善用户体验
3. ✅ 长期具有无限扩展潜力
4. ✅ 零成本（所有数据源开源）
5. ✅ 可持续维护和改进
6. ✅ 符合项目的"简单、适用、演进"原则

### 分阶段计划

**第 1 周: 快速覆盖（实施方案 B 的核心）**
```
任务:
  1. 收集 BNC + COCA 数据
  2. 编写数据合并脚本
  3. 为新词条添加中文翻译
  4. 生成新的 cefr_words.json
  5. 测试验证

结果:
  - 词库从 6,860 → 18,000 词
  - 用户体验立即改善
```

**第 2-3 周: 基础设施准备（方案 C 的数据层）**
```
任务:
  1. 数据库添加 cached_words 表
  2. 实现智能查询逻辑（本地 → 缓存）
  3. 集成 Free Dictionary API
  4. 实现缓存策略和预加载

结果:
  - 为动态词汇查询做准备
```

**第 4+ 周: 灰度和全量推出**
```
任务:
  1. 灰度发布（5% → 50% → 100% 用户）
  2. 监控性能和准确率
  3. 收集用户反馈
  4. 持续优化

结果:
  - 完整的词汇解决方案
  - 支持无限词汇查询
```

---

## 七、后续需要讨论的细节

1. **中文翻译方案**
   - 使用 API 自动翻译还是手工维护？
   - 如何处理多义词？

2. **难度评估规则**
   - 如何评估新词的 CEFR 等级？
   - 是否使用词频排名作为辅助？

3. **缓存策略**
   - 预加载哪些常见词？
   - 缓存过期时间多长？

4. **性能指标**
   - 能接受的最大查询延迟？
   - 缓存命中率目标？

5. **优先功能**
   - 是否先解决中文翻译覆盖率？
   - 是否需要词汇分类（按难度、领域等）？

---

## 总结

| 方案 | 适用场景 | 推荐度 |
|------|---------|--------|
| A | 最小投入，快速扩展到 12K | ⭐⭐ |
| B | 性价比最优，快速到 20K | ⭐⭐⭐⭐ |
| C | 长期无限扩展 | ⭐⭐⭐⭐ |
| D | 最高质量，但有成本 | ⭐⭐ |
| **E** | **综合最优** | **⭐⭐⭐⭐⭐** |

**最终推荐：采用方案 E（第一周实施方案 B，后续逐步完善方案 C）**

---

## 下一步行动

请回答以下问题，我们可以更精确地定制实施计划：

1. ✅ 是否同意采用方案 E？
2. ✅ 第 1 周能否投入 2-3 天完成数据合并？
3. ✅ 中文翻译的优先级有多高？
4. ✅ 是否希望包含专业词汇（医学、科技等）？
5. ✅ 有具体的用户反馈词汇列表吗？（如 proficiency, exposure 等）

